import requests
import time
import csv
from bs4 import BeautifulSoup


class NBAScraper():

    def __init__(self):
        self.url = "https://www.basketball-reference.com"
        self.subdomain = "/leagues/NBA_2020_games.html"
        self.data = []

    def __download_html(self, url):
        page = requests.get(url)
        html = page.content
        return html

    def __get_month_games(self, subdomain):
        # Download HTML
        html = self.__download_html(self.url + subdomain)
        bs = BeautifulSoup(html, 'html.parser')

        for element in bs.select('td[data-stat*="box_score_text"]'):
            if element.a is not None:
                self.data.extend(self.__get_game_data(subdomain=element.a['href'],
                                                      game_date=((element.a['href'].split("/", 2))[2])[0:8]))

    def __get_game_data(self, subdomain, game_date):
        # Download HTML
        html = self.__download_html(self.url + subdomain)
        bs = BeautifulSoup(html, 'html.parser')

        game_data = []

        # Get the two teams names
        teams_info = bs.select('div[itemprop*="performer"]')
        visitor_team = teams_info[0].strong.a.getText()
        local_team = teams_info[1].strong.a.getText()

        # Get the two teams scores and winner
        scores_info = bs.select('div[class*="scores"]')
        visitor_score = scores_info[0].div.getText()
        local_score = scores_info[1].div.getText()

        # Get the two game basic tables fow the two teams
        for element in bs.select('table[id*="game-basic"]'):

            # Get team name from the <caption> of the table
            team_name = element.caption.getText().split("(")[0]
            team_name = team_name[:-1]

            # Get players from the table
            for table_player in element.tbody.select('th[class*="left"]'):

                # We eliminate players that "Did Not Play" or "Did Not Dress" or "Not With Team" or ...
                if table_player.next_sibling.get("data-stat") != "reason":
                    player = table_player.a.getText()

                    data_row = {"date": game_date, "team": team_name}
                    if team_name == local_team:
                        data_row["against"] = visitor_team
                        data_row["local"] = True
                        data_row["team_score"] = local_score
                        data_row["rival_score"] = visitor_score
                        data_row["result"] = ("Win" if local_score > visitor_score else "Lose")
                    else:
                        data_row["against"] = local_team
                        data_row["local"] = False
                        data_row["team_score"] = visitor_score
                        data_row["rival_score"] = local_score
                        data_row["result"] = ("Win" if local_score < visitor_score else "Lose")
                    data_row["player"] = player

                    # Get stats for each player
                    for stat in table_player.next_siblings:
                        data_row[stat['data-stat']] = stat.getText()

                    game_data.append(data_row)

        # Get the two game advanced tables fow the two teams
        for element in bs.select('table[id*="game-advanced"]'):

            # Get players from the table
            for table_player in element.tbody.select('th[class*="left"]'):

                # We eliminate players that "Did Not Play" or "Did Not Dress" or "Not With Team" or ...
                if table_player.next_sibling.get("data-stat") != "reason":
                    player = table_player.a.getText()

                    # Get stats for each player
                    for stat in table_player.next_siblings:
                        next(item for item in game_data if item["player"] == player).update(
                            {stat['data-stat']: stat.getText()})

        return game_data

    def data2csv(self, filename):
        # Overwrite to the specified file.
        # Create it if it does not exist.
        file = open("../csv/" + filename, "w+")

        # Dump all the data with CSV format
        keys = self.data[0].keys()
        dict_writer = csv.DictWriter(file, keys)
        dict_writer.writeheader()
        dict_writer.writerows(self.data)

    def scrape(self):
        print("Web Scraping of NBA match " + "'" + self.url + "'...")

        print("This process could take roughly 50 minutes.\n")

        # Start timer
        start_time = time.time()

        # Download HTML
        html = self.__download_html(self.url + self.subdomain)
        bs = BeautifulSoup(html, 'html.parser')

        # Get all the matches for one month
        element = bs.select('div[class*="filter"]')[0]

        for month in element.find_all("a"):
            print("Getting info from month: " + month["href"])
            self.__get_month_games(month["href"])

        self.data2csv("nba_2020_data.csv")

        # Show elapsed time
        end_time = time.time()
        print("\nelapsed time: " + \
              str(round(((end_time - start_time) / 60), 2)) + " minutes")
